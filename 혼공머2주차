# 03-1 k-최근접 이웃 회귀

## k-최근접 이웃 회귀

지도 학습 알고리즘 → 분류, 회귀

분류 : 샘플을 몇 개의 클래스 중 하나로 분류

회귀 : 임의의 어떤 숫자를 예측 ex) 농어 무게 예측, 경제 성장률 예측

 

k-최근접 이웃 회귀 알고리즘

→ 예측하려는 샘플에 가장 가까운 샘플 k개 선택(회귀이므로 가까운 샘플은 클래스가 아니라 수치)

→ 샘플(수치) 들의 평균을 구해서 예측을 구함.

→ ex. 샘플 = {100, 60, 80}, 예측하려는 샘플 = k, k의 예측 값 = (100+60+80)/3 = 80

## 결정계수

```jsx
knr = KNeighborsRegressor()
# k-최근접 이웃 회귀 모델을 훈련합니다
knr.fit(train_input, train_target)
knr.score(test_input, test_target)

output
0.992809406101064
```

k-최근접 이웃 회귀 알고리즘으로 회귀 모델을 실행시켜보았을 때 나오는 수의 의미는?

→  결정계수 : 회귀에서 예측 값을 평가하는 수

→ 타깃의 평균 정도를 예측한다? → 결정계수는 0에 가까워짐

→ 에측이 타깃에 아주 가까워지면? → 1에 가까워지는 값이 나옴

위의 코드에서는 약 0.99 정도 나오는데 1에 매우 가까운 값임, 잘 나온 값이라고 할 수 있음

❓ 근데 얼마나 좋은 값인지 어떻게 알지?

→ 타깃과 예측한 값 사이의 차이를 구해서 어느정도 예측이 벗어났는지 확인

```jsx
# 테스트 세트에 대한 예측을 만듭니다
test_prediction = knr.predict(test_input)
# 테스트 세트에 대한 평균 절댓값 오차를 계산합니다
mae = mean_absolute_error(test_target, test_prediction)
print(mae)

OUTPUT
19.157142857142862
```

→ 결과에서 예측이 평균적으로 19g 정도 타깃값과 다르다는 것을 알 수 있음.

## 과대적합 vs 과소적합

교재 예시에서 train set 으로 모델을 실행했을 때 결정계수가 약 0.96, test set 으로 실행했을 때 약 0.99

→ 과소 적합

과대 적합 : 훈련 셋에서는 점수가 좋음 + 테스트 셋에서는 점수가 낮음 → 과대적합(overfitting)

과소 적합 : 훈련 셋보다 테스트 셋의 점수가 높음 or 둘 다 점수가 낮음 → 과소적합(underfitting)

❓ 어떻게 해결? → 모델을 좀 더 복잡하게, 훈련 셋에 더 잘 맞게 수정

→ k의 개수를 줄임, k(이웃의 개수)를 줄이면 훈련 셋의 패턴에 민감해질것이다

(반대로, k의 개수를 늘린다면 일반적엔 전체 데이터의 패턴에 따르게 될것임)

## 03-1 마지막 정리

1. 클래스를 구별하는 분류와 달리, 임의의 수치를 예측하는 것을 회귀 라고함
2. k-최근접 이웃 회귀 모델은 가장 가까운 k개의 이웃을 찾고, 이웃 샘플의 타깃값을 평균하여 이 샘플의 예측값으로 사용
3. 회귀 모델의 성능을 평가하는 점수는 결정계수, 1에 가까울수록 좋음
4. 모델을 train/test set 으로 모두 학습해봤을 때, train set의 점수가 더 높다 → overfitting, test set 의 점수가 더 높다 혹은 둘 다 점수가 낮다 → underfitting
5. underfitting일 경우 k 값을 줄여서 trainset 의 점수를 높이고, testset의 점수가 낮아지도록
6. overfitting일 경우 k값을 늘려서 trainset에만 적합하게 반응하지않고 전체적인 데이터의 패턴에 따르도록

# 03-2 선형 회귀

## 선형회귀

주어진 데이터에 가장 잘 맞는 직선을 찾아, 새로운 값이 들어왔을 때 결과를 예측하는 방법

![image.png](attachment:2ebccfdb-cbd8-4509-bc34-50941c7749f6:image.png)

y = ax+b 형식으로 쓸 수 있음

기울기(a) 를 계수, 가중치 라고 부름, 그리고 이걸 모델 파라미터 라고 하는데 우리는 학습을 반복하면서 최적의 파라미터를 찾는게 목표임

## 다항 회귀

다항회귀는 직선이 아니라 곡선으로 데이터를 설명하는 선형회귀의 확장 버전

→ 선형회귀는 y=ax+b 처럼 **직선(line)** 하나로 데이터를 설명. 하지만 현실의 데이터는 꼭 직선 모양이 아닐 수 있다. 즉, 곡선 형태 일 수도 있다는 의미

그래서 다항회귀에서는 **x², x³ 같은 항을 추가**해서 곡선을 만들어냄. y=a0+a1x+a2x2+a3x3+…

![image.png](attachment:a06a772d-38fa-4509-b075-e1961fadaa73:image.png)

# 03-3 특성 공학과 규제

## 다중 회귀

이때까지는 하나의 특성을 사용한 모델의 학습 결과를 토대로 설명했음 → 선형 회귀

여러 개의 특성을 사용한 선형 회귀 → 다중 회귀

❓ 특성을 1개 사용했을 때 선형 회귀 모델이 학습한 것은 직선. 2개를 사용한다면? → 평면을 학습

타깃 = a*특성1 + b*특성2 + 절편 이라서 평면이 된다. (변수 3개 이상부터는 3차원 이상)

특성 공학 : 기존 특성을 이용해서 새로운 특성을 뽑아내는 작업 ex. 농어 길이 * 농어 높이 를 새로운 특성으로

❓ 특성 공학을 왜 해?

→  다중 회귀 모델의 기본 형태는 y=a1x1+a2x2+a3x3+b. 즉, **모든 변수(x)** 들이 **독립적으로 y에 선형적으로 영향을 준다**고 가정함. 하지만 현실의 데이터는 모두가 선형적으로 영향을 준다고 할 수 없음

**그래서 사용하는게 특성공학 = 입력 데이터를 모델이 이해하기 쉽게 다시 표현하는 과정**

즉, **모델이 놓치고 있는 관계나 패턴을 새 특성으로 만들어서 추가하는 것**.

x1 = 농어 길이, x2 = 농어 높이 일 때, 이렇게 새 특성을 넣으면 y=a1x1+a2x2+a3(x1x2)+b 이런 형태로 모델이 “변수 간 상호작용”을 학습할 수 있음

```jsx
poly = PolynomialFeatures(degree=5, include_bias=False)

poly.fit(train_input)
train_poly = poly.transform(train_input)
test_poly = poly.transform(test_input)
print(train_poly.shape)

output
(42, 55)
```

---

교재 예시에서 다중 회귀를 진행하려고 데이터 준비하면서 특성 공학으로 새로운 특성 만들었는데

무려 55개나 만들었음. 근데 이렇게 많다고 좋을까?

```jsx
lr.fit(train_poly, train_target)
print(lr.score(train_poly, train_target))

output
0.9999999999996433
```

오 train set 에 대한 모델의 학습 결과로는 매우 좋음(1에 매우 가까우니까)

```jsx
print(lr.score(test_poly, test_target))

output
-144.40579436844948
```

 엥 음수가 나옴. 왜? → 특성의 개수를 너무 많이 늘려서

특성의 개수를 늘리면 훈련 셋에 대해 거의 완벽하게 학습할 수 있음(위에 0.999 결과)

하지만 이렇게되면 훈련 셋에 과적합(overfitting) 상태가 되기 때문에 테스트 셋에서는 형편없음

그럼 특성을 적당히 줄여야겠죠?

## 규제

머신러닝 모델이 훈련 셋을 너무 과도하게 학습하지 못하도록 훼방하는 것(즉, overfitting 방지)

규제에는 두 가지가 있다 → 릿지 와 라쏘

1. 릿지 : 계수를 제곱한 값을 기준으로 규제를 적용(일반적으로 릿지를 좀 더 선호)
2. 라쏘 : 계수의 절댓값을 기준으로 규제 적용 

릿지와 라쏘 모델을 사용할 때 구제의 양의 조절할 수 있는데, 모델 객체를 만들 때 alpha 매개변수로 규제의 강도 조절. alpha 값이 커지면 → 규제의 강도 세지므로 계수 값을 줄이고. alpha 값이 작아지면 → 계수를 줄이는 역할이 줄어든다.

## 릿지 회귀

alpha 값을 0.001 부터 100 까지 10씩 늘리며 릿지 회귀모델을 학습해 보았을 때

![image.png](attachment:72afd230-b24a-4a43-959a-dea354efcd8d:image.png)

파랑 : 훈련 셋 그래프, 주황 : 테스트셋 그래프

그래프 분석 : 왼쪽은 훈련 셋과 테스트 셋 사이의 점수 차가 너무 큼. (overfitting 형태). 오른쪽은 훈련셋과 데이터 셋 모두 점수가 낮아지는 과소적합 형태

적절한 alpha 값은 1. 두 그래프가 가장 가깝고, 2. 테스트 셋의 점수가 가장 큰 -1 지점. 즉, 0.1 임

## 라쏘 회귀

alpha 값을 0.001 부터 100 까지 10씩 늘리며 라쏘 회귀모델을 학습해 보았을 때

![image.png](attachment:3f3829c9-4690-489d-87d6-bf487e212124:image.png)

파랑 : 훈련 셋 그래프, 주황 : 테스트셋 그래프

그래프 분석 : 왼쪽은 과대적합 형태, 오른쪽으로 갈수록 훈련 셋과 테스트 셋의 점수가 점점 좁혀지고 있다.

가장 오른쪽에서는 둘 다 점수가 크게 떨어짐(과소적합 형태).

가장 적절한 alpha 값은 1. 즉, 10 일 때 임

❓ 근데 리쏘 모델은 계수 값을 아예 0 으로 만들 수 있는데, 그럼 0으로 규제 당한 값들은 뭘까?

→ 라쏘는 중요하지 않은 변수를 완전히 제거해서 모델을 단순화한다 라고 볼 수 있음. 

불필요한 변수의 계수를 0으로 만들어서, 특성 선택(feature selection) 이 자동으롱 일어나게 함

ex.)

| 변수 | 원래 회귀 계수 | 라쏘 적용 후 |
| --- | --- | --- |
| 공부 시간 | 0.9 | 0.85 |
| 수면 시간 | 0.4 | 0.00 ❌ |
| 커피 섭취량 | -0.2 | -0.05 |

여기서 **수면 시간의 계수가 0**이 되었다는 건 : 이 변수는 결과 예측에 거의 도움 되지 않으니까 무시할게~

---

계수가 0이 되면? 결과적으로 **모델이 단순해지고, 과적합(overfitting)을 방지**

## 규제 값(alpha) 을 바꿔보면서 어떻게 변하는지 보기(릿지)

| alpha | score |
| --- | --- |
| 0.001 | 0.9502 |
| 0.01 | 0.9498 |
| 0.1 | 0.9489 |
| 1 | 0.9401 |
| 10 | 0.9002 |
| 100 | 0.7403 |

---
